分P编号：91
视频标题：91_大模型的本地化部署
内容总结：
本内容为黑马程序员零基础具身智能机械臂实战课程**「大模型本地化部署」章节**的结构化总结，共分4个要点：

---

### 要点1：大模型本地化部署的核心必要性
**核心知识点**：
1. 传统API云调用大模型方案存在固有安全风险：所有用户输入数据必须上传至大模型厂商服务器，且默认开启用户数据收集用于模型训练，存在数据被窃听、泄露的风险，行业内已发生三星员工上传机密芯片数据导致核心数据外泄的安全事故。
2. 政府、涉密企业等对数据安全合规要求高的场景，云调用方案无法满足要求，必须通过本地化部署实现**数据全流程不出本地私有环境**，从根源消除安全风险。

---

### 要点2：本地化部署选型：DeepSeek大模型的适配优势
**核心知识点**：
1. DeepSeek是真正全开源的大模型，开放全部模型结构、参数权重、源代码、训练方法，支持用户自主做安全审计，完全符合私有化部署的安全要求。
2. DeepSeek是国内首个实现开源深度思考能力的大模型，其R1版本的深度思考技术已成为行业标杆，被全球主流大模型借鉴，能力足够满足商用/项目开发需求。

---

### 要点3：模型压缩技术与不同规模部署的硬件成本要求
**核心知识点**：
1. 三类主流模型压缩技术可将大模型适配不同硬件环境：
   - 蒸馏：用大模型监督训练小模型，保留大模型核心能力的同时降低参数规模
   - 裁剪：移除不需要的专业领域冗余参数，缩小模型体积
   - 量化：将高精度32位浮点数替换为低精度int8整数，大幅降低内存占用
2. 不同参数规模的部署要求：
   | 模型规模 | 硬件要求 | 部署成本 | 适用场景 |
   |----------|----------|----------|----------|
   | 完整版671B | 原方案需8块英伟达H800；现华为昇腾国产方案可适配 | 原方案180万，国产方案24~30万 | 企业商用全功能部署 |
   | 压缩版70B | 中端专业GPU集群 | 约12万 | 企业场景中轻度需求 |
   | 中规模14B/32B | RTX4070及以上消费级显卡 | 万元以内 | 开发者项目测试 |
   | 轻量化1.5B | 普通PC 8G内存即可运行 | 零额外成本 | 个人体验学习 |

---

### 要点4：普通PC轻量化部署实战方案（基于Ollama工具）
**核心操作与知识点**：
1. Ollama定位：开源轻量化大模型部署工具，优势为开源开放、易用性强、成本极低，支持上百种开源大模型，涵盖三类主流模型：带深度思考的通用大模型、支持图像理解的多模态视觉大模型、支持工具调用的大模型；原生支持**MCP模型上下文协议**（本项目中用于实现大模型调用机械臂硬件，让大模型具备实体交互能力）。
2. 部署操作步骤：
   ① 安装：可从官网下载，或使用课程提供的安装包，以管理员身份运行，按引导完成安装即可；安装后后台驻留，仅在系统右下角显示托盘图标，无桌面客户端界面；
   ② 模型选择：通过Ollama官网模型库，选择适配需求的开源模型，原生支持DeepSeek R1、阿里千问等国产主流模型；
   ③ 交互调用：通过命令行完成模型加载与交互。
