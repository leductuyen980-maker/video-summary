分P编号：92
视频标题：92_本地大模型的python调用
内容总结：
本次总结对应黑马程序员具身智能机械臂项目课程中《92_本地大模型的python调用》分P内容，按逻辑分为4个要点：

---
### 1. Ollama（原视频称“欧拉玛”）本地大模型框架部署与运行
**核心操作/注意事项**：
① 安装验证：运行默认安装包，按引导完成安装后，在CMD命令行输入`ollama -v`，输出版本号即代表安装成功。
② 模型启动命令：命令行执行`ollama run <模型名>:<参数量>`，框架会自动下载并启动指定模型，示例：启动1.5B参数的DeepSeek R1命令为`ollama run deepseek-r1:1.5b`。
③ 核心特性与限制：大模型推理完全本地化，断网仍可正常对话；普通带30/40系独显的消费级笔记本最多可运行14B参数模型，推荐新手使用1.5B版本，切勿尝试671B等超大参数模型，避免硬件无法承载。

---
### 2. Python调用本地Ollama大模型的实现方法
**核心知识点/步骤**：
① 调用逻辑：基于Ollama开放的本地API实现调用，仅需指定本地已部署的模型名称、传入用户对话消息，即可获取模型推理回复，课程提供可直接修改使用的模板代码。
② 适配场景：代码运行后断网仍可正常响应通用常识、基础计算类问题；1.5B参数模型可在RK3568/RK3588等嵌入式开发板离线运行，适配嵌入式端离线AI场景需求。

---
### 3. 大模型输出特殊符号问题解析
**核心知识点**：
大模型默认输出Markdown格式（原视频口误为“MacDon”），格式语法为：`#`对应不同层级标题、`*`对应无序列表/加粗，未用Markdown工具打开就会显示为大量杂乱特殊符号；
解决方法：将输出文件后缀改为`.md`，通过Markdown编辑器即可正常渲染出规范排版。

---
### 4. 可视化交互优化方案（基于Chatbox开源工具）
**核心操作/优势**：
① 解决痛点：弥补原生命令行交互输入输出不便的问题，支持统一管理多个云端、本地大模型。
② 安装配置：Chatbox为开源工具，双击安装包按引导即可完成安装；配置本地Ollama时，默认本地地址为`127.0.0.1`，固定端口为`11434`，验证服务运行后即可自动导入所有本地已部署模型；配置云端DeepSeek等模型仅需填入对应API密钥即可完成验证。
③ 使用效果：所有模型可在统一可视化界面切换对话，交互体验远优于命令行。
